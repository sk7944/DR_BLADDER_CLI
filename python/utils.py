#!/usr/bin/env python3
"""
ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
DR-Bladder Agentì˜ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
import subprocess
import shutil
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
import json
import time
from datetime import datetime

# ìƒ‰ìƒ ì¶œë ¥
from colorama import Fore, Style, init
init(autoreset=True)

def setup_logging(log_dir: str = None, log_level: str = "INFO", verbose: bool = False) -> logging.Logger:
    """
    ë¡œê¹… ì„¤ì •
    
    Args:
        log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        log_level: ë¡œê·¸ ë ˆë²¨
        verbose: ìƒì„¸ ë¡œê·¸ ì—¬ë¶€
    
    Returns:
        logging.Logger: ì„¤ì •ëœ ë¡œê±°
    """
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    if not log_dir:
        log_dir = str(Path.home() / ".dr-bladder" / "logs")
    
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì •
    level = getattr(logging, log_level.upper(), logging.INFO)
    
    # ë¡œê±° ìƒì„±
    logger = logging.getLogger("dr-bladder")
    logger.setLevel(level)
    
    # í•¸ë“¤ëŸ¬ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì œê±°
    if logger.handlers:
        logger.handlers.clear()
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    log_file = Path(log_dir) / f"dr-bladder-{datetime.now().strftime('%Y%m%d')}.log"
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(level)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ (verbose ëª¨ë“œì—ì„œë§Œ)
    if verbose:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
    
    # íŒŒì¼ í¬ë§·í„°
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
    )
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)
    
    return logger

def check_system_requirements() -> bool:
    """
    ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
    
    Returns:
        bool: ìš”êµ¬ì‚¬í•­ ë§Œì¡± ì—¬ë¶€
    """
    try:
        print(f"{Fore.BLUE}ğŸ” ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...{Style.RESET_ALL}")
        
        # Python ë²„ì „ í™•ì¸
        python_version = sys.version_info
        if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
            print(f"{Fore.RED}âŒ Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬: {python_version.major}.{python_version.minor}{Style.RESET_ALL}")
            return False
        
        print(f"{Fore.GREEN}âœ… Python {python_version.major}.{python_version.minor}.{python_version.micro}{Style.RESET_ALL}")
        
        # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
        required_packages = [
            'torch', 'transformers', 'sentence_transformers', 
            'chromadb', 'PyPDF2', 'ollama', 'psutil', 'tqdm', 'colorama'
        ]
        
        missing_packages = []
        for package in required_packages:
            try:
                __import__(package)
                print(f"{Fore.GREEN}âœ… {package}{Style.RESET_ALL}")
            except ImportError:
                missing_packages.append(package)
                print(f"{Fore.RED}âŒ {package} (ë¯¸ì„¤ì¹˜){Style.RESET_ALL}")
        
        if missing_packages:
            print(f"{Fore.RED}âŒ ë‹¤ìŒ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: {', '.join(missing_packages)}{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}ğŸ’¡ ì„¤ì¹˜ ëª…ë ¹ì–´: pip install {' '.join(missing_packages)}{Style.RESET_ALL}")
            return False
        
        # Ollama ì„¤ì¹˜ í™•ì¸
        if not check_ollama_installation():
            print(f"{Fore.RED}âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}ğŸ’¡ ì„¤ì¹˜ ë°©ë²•: https://ollama.ai{Style.RESET_ALL}")
            return False
        
        print(f"{Fore.GREEN}âœ… ëª¨ë“  ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•©ë‹ˆë‹¤.{Style.RESET_ALL}")
        return True
        
    except Exception as e:
        print(f"{Fore.RED}âŒ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì‹¤íŒ¨: {str(e)}{Style.RESET_ALL}")
        return False

def check_ollama_installation() -> bool:
    """
    Ollama ì„¤ì¹˜ í™•ì¸
    
    Returns:
        bool: Ollama ì„¤ì¹˜ ì—¬ë¶€
    """
    try:
        # ollama ëª…ë ¹ì–´ ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        result = subprocess.run(['ollama', '--version'], 
                              capture_output=True, text=True, timeout=5)
        
        if result.returncode == 0:
            print(f"{Fore.GREEN}âœ… Ollama ì„¤ì¹˜ë¨: {result.stdout.strip()}{Style.RESET_ALL}")
            return True
        else:
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
        return False

def check_ollama_service() -> bool:
    """
    Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ ìƒíƒœ í™•ì¸
    
    Returns:
        bool: ì„œë¹„ìŠ¤ ì‹¤í–‰ ì—¬ë¶€
    """
    try:
        import requests
        response = requests.get('http://localhost:11434/api/tags', timeout=5)
        return response.status_code == 200
    except:
        return False

def check_model_availability(model_name: str) -> bool:
    """
    Ollama ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    
    Args:
        model_name: í™•ì¸í•  ëª¨ë¸ ì´ë¦„
    
    Returns:
        bool: ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    """
    try:
        import ollama
        client = ollama.Client()
        models = client.list()
        model_names = [model['name'] for model in models['models']]
        return model_name in model_names
    except:
        return False

def get_system_info() -> Dict[str, Any]:
    """
    ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
    
    Returns:
        Dict: ì‹œìŠ¤í…œ ì •ë³´
    """
    try:
        import psutil
        import torch
        
        # ê¸°ë³¸ ì‹œìŠ¤í…œ ì •ë³´
        info = {
            "os": os.name,
            "platform": sys.platform,
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
            "architecture": os.uname().machine if hasattr(os, 'uname') else 'unknown'
        }
        
        # CPU ì •ë³´
        info["cpu"] = {
            "count": psutil.cpu_count(),
            "percent": psutil.cpu_percent(interval=1),
            "frequency": psutil.cpu_freq().current if psutil.cpu_freq() else None
        }
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory = psutil.virtual_memory()
        info["memory"] = {
            "total": memory.total,
            "available": memory.available,
            "percent": memory.percent,
            "used": memory.used
        }
        
        # GPU ì •ë³´
        info["gpu"] = {
            "available": torch.cuda.is_available(),
            "count": torch.cuda.device_count() if torch.cuda.is_available() else 0
        }
        
        if torch.cuda.is_available():
            info["gpu"]["devices"] = []
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                info["gpu"]["devices"].append({
                    "name": props.name,
                    "total_memory": props.total_memory,
                    "memory_allocated": torch.cuda.memory_allocated(i),
                    "memory_reserved": torch.cuda.memory_reserved(i)
                })
        
        # ë””ìŠ¤í¬ ì •ë³´
        disk = psutil.disk_usage('/')
        info["disk"] = {
            "total": disk.total,
            "used": disk.used,
            "free": disk.free,
            "percent": (disk.used / disk.total) * 100
        }
        
        return info
        
    except Exception as e:
        return {"error": str(e)}

def format_bytes(bytes_value: int) -> str:
    """
    ë°”ì´íŠ¸ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
    
    Args:
        bytes_value: ë°”ì´íŠ¸ ê°’
    
    Returns:
        str: í¬ë§·ëœ ë¬¸ìì—´
    """
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.1f}{unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.1f}PB"

def format_time(seconds: float) -> str:
    """
    ì´ˆë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
    
    Args:
        seconds: ì´ˆ ê°’
    
    Returns:
        str: í¬ë§·ëœ ë¬¸ìì—´
    """
    if seconds < 60:
        return f"{seconds:.1f}ì´ˆ"
    elif seconds < 3600:
        minutes = seconds // 60
        remaining_seconds = seconds % 60
        return f"{int(minutes)}ë¶„ {remaining_seconds:.1f}ì´ˆ"
    else:
        hours = seconds // 3600
        remaining_minutes = (seconds % 3600) // 60
        return f"{int(hours)}ì‹œê°„ {int(remaining_minutes)}ë¶„"

def create_progress_bar(current: int, total: int, width: int = 50) -> str:
    """
    ì§„í–‰ë¥  ë°” ìƒì„±
    
    Args:
        current: í˜„ì¬ ê°’
        total: ì „ì²´ ê°’
        width: ë°” ë„ˆë¹„
    
    Returns:
        str: ì§„í–‰ë¥  ë°”
    """
    if total == 0:
        return "[" + "=" * width + "]"
    
    progress = current / total
    filled = int(width * progress)
    empty = width - filled
    
    bar = "[" + "=" * filled + ">" + " " * empty + "]"
    percentage = progress * 100
    
    return f"{bar} {percentage:.1f}% ({current}/{total})"

def save_json(data: Any, file_path: str, indent: int = 2) -> bool:
    """
    JSON íŒŒì¼ ì €ì¥
    
    Args:
        data: ì €ì¥í•  ë°ì´í„°
        file_path: íŒŒì¼ ê²½ë¡œ
        indent: ë“¤ì—¬ì“°ê¸°
    
    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=indent, ensure_ascii=False)
        return True
    except Exception as e:
        logging.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def load_json(file_path: str) -> Optional[Any]:
    """
    JSON íŒŒì¼ ë¡œë“œ
    
    Args:
        file_path: íŒŒì¼ ê²½ë¡œ
    
    Returns:
        Optional[Any]: ë¡œë“œëœ ë°ì´í„° ë˜ëŠ” None
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logging.error(f"JSON ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

def ensure_directory(directory: str) -> bool:
    """
    ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸ ë° ìƒì„±
    
    Args:
        directory: ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        Path(directory).mkdir(parents=True, exist_ok=True)
        return True
    except Exception as e:
        logging.error(f"ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return False

def clean_text_for_display(text: str, max_length: int = 100) -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ í™”ë©´ ì¶œë ¥ìš©ìœ¼ë¡œ ì •ë¦¬
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        max_length: ìµœëŒ€ ê¸¸ì´
    
    Returns:
        str: ì •ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    # ì¤„ë°”ê¿ˆ ë° ì—°ì† ê³µë°± ì œê±°
    cleaned = ' '.join(text.split())
    
    # ê¸¸ì´ ì œí•œ
    if len(cleaned) > max_length:
        cleaned = cleaned[:max_length-3] + "..."
    
    return cleaned

def validate_url(url: str) -> bool:
    """
    URL ìœ íš¨ì„± ê²€ì‚¬
    
    Args:
        url: í™•ì¸í•  URL
    
    Returns:
        bool: ìœ íš¨ì„± ì—¬ë¶€
    """
    try:
        import re
        pattern = r'^https?://(?:[-\w.])+(?:\:[0-9]+)?(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:\#(?:[\w.])*)?)?$'
        return bool(re.match(pattern, url))
    except:
        return False

def test_ollama_connection(host: str = "http://localhost:11434") -> Dict[str, Any]:
    """
    Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
    
    Args:
        host: Ollama í˜¸ìŠ¤íŠ¸
    
    Returns:
        Dict: ì—°ê²° í…ŒìŠ¤íŠ¸ ê²°ê³¼
    """
    try:
        import requests
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        response = requests.get(f"{host}/api/tags", timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            models = [model['name'] for model in data.get('models', [])]
            
            return {
                "connected": True,
                "models": models,
                "model_count": len(models),
                "message": "ì—°ê²° ì„±ê³µ"
            }
        else:
            return {
                "connected": False,
                "error": f"HTTP {response.status_code}",
                "message": "ì—°ê²° ì‹¤íŒ¨"
            }
    
    except requests.exceptions.ConnectionError:
        return {
            "connected": False,
            "error": "ì—°ê²° ì˜¤ë¥˜",
            "message": "Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        return {
            "connected": False,
            "error": str(e),
            "message": "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }

def benchmark_system() -> Dict[str, Any]:
    """
    ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    
    Returns:
        Dict: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
    """
    try:
        import time
        import torch
        
        results = {}
        
        # CPU ë²¤ì¹˜ë§ˆí¬
        start_time = time.time()
        # ê°„ë‹¨í•œ ê³„ì‚° ì‘ì—…
        result = sum(i * i for i in range(100000))
        cpu_time = time.time() - start_time
        results["cpu_benchmark"] = {
            "time": cpu_time,
            "ops_per_second": 100000 / cpu_time if cpu_time > 0 else 0
        }
        
        # GPU ë²¤ì¹˜ë§ˆí¬ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if torch.cuda.is_available():
            start_time = time.time()
            # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚°
            device = torch.device("cuda:0")
            tensor = torch.randn(1000, 1000, device=device)
            result = torch.mm(tensor, tensor)
            torch.cuda.synchronize()
            gpu_time = time.time() - start_time
            
            results["gpu_benchmark"] = {
                "time": gpu_time,
                "device": torch.cuda.get_device_name(0),
                "memory_allocated": torch.cuda.memory_allocated(0),
                "memory_reserved": torch.cuda.memory_reserved(0)
            }
        
        return results
        
    except Exception as e:
        return {"error": str(e)}

def print_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥"""
    print(f"\n{Fore.CYAN}ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ{Style.RESET_ALL}")
    print("=" * 50)
    
    # ì‹œìŠ¤í…œ ì •ë³´
    info = get_system_info()
    
    print(f"{Fore.YELLOW}ğŸ–¥ï¸  ì‹œìŠ¤í…œ ì •ë³´:{Style.RESET_ALL}")
    print(f"  â€¢ OS: {info.get('os', 'Unknown')} ({info.get('platform', 'Unknown')})")
    print(f"  â€¢ Python: {info.get('python_version', 'Unknown')}")
    print(f"  â€¢ ì•„í‚¤í…ì²˜: {info.get('architecture', 'Unknown')}")
    
    # CPU ì •ë³´
    cpu = info.get('cpu', {})
    print(f"\n{Fore.YELLOW}ğŸ”§ CPU ì •ë³´:{Style.RESET_ALL}")
    print(f"  â€¢ ì½”ì–´ ìˆ˜: {cpu.get('count', 'Unknown')}")
    print(f"  â€¢ ì‚¬ìš©ë¥ : {cpu.get('percent', 0):.1f}%")
    if cpu.get('frequency'):
        print(f"  â€¢ ì£¼íŒŒìˆ˜: {cpu.get('frequency', 0):.1f} MHz")
    
    # ë©”ëª¨ë¦¬ ì •ë³´
    memory = info.get('memory', {})
    print(f"\n{Fore.YELLOW}ğŸ’¾ ë©”ëª¨ë¦¬ ì •ë³´:{Style.RESET_ALL}")
    print(f"  â€¢ ì „ì²´: {format_bytes(memory.get('total', 0))}")
    print(f"  â€¢ ì‚¬ìš© ì¤‘: {format_bytes(memory.get('used', 0))} ({memory.get('percent', 0):.1f}%)")
    print(f"  â€¢ ì‚¬ìš© ê°€ëŠ¥: {format_bytes(memory.get('available', 0))}")
    
    # GPU ì •ë³´
    gpu = info.get('gpu', {})
    print(f"\n{Fore.YELLOW}ğŸ® GPU ì •ë³´:{Style.RESET_ALL}")
    if gpu.get('available'):
        print(f"  â€¢ GPU ê°œìˆ˜: {gpu.get('count', 0)}")
        for i, device in enumerate(gpu.get('devices', [])):
            print(f"  â€¢ GPU {i}: {device.get('name', 'Unknown')}")
            print(f"    - ì „ì²´ ë©”ëª¨ë¦¬: {format_bytes(device.get('total_memory', 0))}")
            print(f"    - ì‚¬ìš© ì¤‘: {format_bytes(device.get('memory_allocated', 0))}")
    else:
        print(f"  â€¢ GPU ì‚¬ìš© ë¶ˆê°€")
    
    # ë””ìŠ¤í¬ ì •ë³´
    disk = info.get('disk', {})
    print(f"\n{Fore.YELLOW}ğŸ’¿ ë””ìŠ¤í¬ ì •ë³´:{Style.RESET_ALL}")
    print(f"  â€¢ ì „ì²´: {format_bytes(disk.get('total', 0))}")
    print(f"  â€¢ ì‚¬ìš© ì¤‘: {format_bytes(disk.get('used', 0))} ({disk.get('percent', 0):.1f}%)")
    print(f"  â€¢ ì‚¬ìš© ê°€ëŠ¥: {format_bytes(disk.get('free', 0))}")
    
    # Ollama ì—°ê²° ìƒíƒœ
    ollama_status = test_ollama_connection()
    print(f"\n{Fore.YELLOW}ğŸ¤– Ollama ìƒíƒœ:{Style.RESET_ALL}")
    if ollama_status.get('connected'):
        print(f"  â€¢ ìƒíƒœ: {Fore.GREEN}ì—°ê²°ë¨{Style.RESET_ALL}")
        print(f"  â€¢ ëª¨ë¸ ìˆ˜: {ollama_status.get('model_count', 0)}")
        models = ollama_status.get('models', [])
        if models:
            print(f"  â€¢ ì„¤ì¹˜ëœ ëª¨ë¸: {', '.join(models[:3])}")
            if len(models) > 3:
                print(f"    ... ë° {len(models) - 3}ê°œ ë”")
    else:
        print(f"  â€¢ ìƒíƒœ: {Fore.RED}ì—°ê²° ì•ˆë¨{Style.RESET_ALL}")
        print(f"  â€¢ ì˜¤ë¥˜: {ollama_status.get('error', 'Unknown')}")
    
    print()

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print_system_status()